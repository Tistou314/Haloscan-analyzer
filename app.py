"""
Haloscan SEO Diff Analyzer
Analyse des diffÃ©rentiels de positions SEO entre deux pÃ©riodes
ConÃ§u pour traiter des fichiers volumineux (250k+ lignes)
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
from datetime import datetime

# Configuration de la page
st.set_page_config(
    page_title="Haloscan SEO Diff Analyzer",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ©
st.markdown("""
<style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 0.5rem;
        color: white;
    }
    .loss { color: #EF4444; }
    .gain { color: #22C55E; }
    .stable { color: #6B7280; }
    .out { color: #F97316; }
    .stMetric > div {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_data
def load_data(uploaded_file):
    """Charge et parse le fichier CSV avec dÃ©tection automatique du sÃ©parateur"""
    try:
        # Essai avec point-virgule d'abord (format Haloscan habituel)
        df = pd.read_csv(uploaded_file, sep=';', encoding='utf-8')
        if len(df.columns) < 5:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, sep=',', encoding='utf-8')
    except UnicodeDecodeError:
        uploaded_file.seek(0)
        try:
            df = pd.read_csv(uploaded_file, sep=';', encoding='latin-1')
            if len(df.columns) < 5:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, sep=',', encoding='latin-1')
        except:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, sep=';', encoding='cp1252')
    
    # Normalisation des noms de colonnes
    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')
    
    # Renommage des colonnes courantes Haloscan
    column_mapping = {
        'mot-clÃ©_(mc)': 'mot_cle',
        'mot-clÃ©': 'mot_cle',
        'mc': 'mot_cle',
        'keyword': 'mot_cle',
        'derniÃ¨re_pos': 'derniere_pos',
        'derniere_pos': 'derniere_pos',
        'position': 'derniere_pos',
        'vieille_pos': 'ancienne_pos',
        'plus_vieille_pos': 'ancienne_pos',
        'old_pos': 'ancienne_pos',
        'meilleure_pos': 'meilleure_pos',
        'best_pos': 'meilleure_pos',
        'pos_perdues': 'pos_perdues',
        'diff_pos': 'diff_pos',
        'diff': 'diff_pos',
        'volume': 'volume',
        'vol': 'volume',
        'volumeh': 'volumeh',
        'statut': 'statut',
        'status': 'statut',
        'trafic': 'trafic',
        'traffic': 'trafic',
        'url': 'url',
        'cpc': 'cpc',
        'comp': 'competition',
        'competition': 'competition'
    }
    
    df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})
    
    # Conversion des colonnes numÃ©riques
    numeric_cols = ['derniere_pos', 'ancienne_pos', 'meilleure_pos', 'diff_pos', 'pos_perdues', 'volume', 'volumeh', 'trafic', 'cpc']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    return df


def calculate_priority_score(row):
    """Calcule le score de prioritÃ© pour un mot-clÃ©"""
    volume = row.get('volume', 0) or 0
    diff = abs(row.get('diff_pos', 0) or 0)
    ancienne_pos = row.get('ancienne_pos', 100) or 100
    
    # Facteur de position : plus on Ã©tait haut, plus c'est grave de perdre
    if ancienne_pos <= 3:
        facteur = 3
    elif ancienne_pos <= 10:
        facteur = 2
    elif ancienne_pos <= 20:
        facteur = 1.5
    else:
        facteur = 1
    
    return volume * diff * facteur


def calculate_recovery_potential(row):
    """Calcule le potentiel de rÃ©cupÃ©ration"""
    volume = row.get('volume', 0) or 0
    meilleure_pos = row.get('meilleure_pos', 100) or 100
    if meilleure_pos == 0:
        meilleure_pos = 1
    return volume / meilleure_pos


def get_status_color(statut):
    """Retourne la couleur associÃ©e au statut"""
    statut = str(statut).lower()
    if 'perd' in statut or 'lost' in statut or 'down' in statut:
        return '#EF4444'
    elif 'gagn' in statut or 'gain' in statut or 'up' in statut:
        return '#22C55E'
    elif 'stable' in statut:
        return '#6B7280'
    elif 'sort' in statut or 'out' in statut:
        return '#F97316'
    elif 'nouveau' in statut or 'new' in statut:
        return '#3B82F6'
    return '#6B7280'


def generate_report(df, df_filtered, kpis):
    """GÃ©nÃ¨re le rapport textuel pour l'Ã©quipe contenu"""
    
    # Top 5 URLs impactÃ©es
    if 'url' in df_filtered.columns:
        url_impact = df_filtered[df_filtered['diff_pos'] < 0].groupby('url').agg({
            'mot_cle': 'count',
            'volume': 'sum',
            'trafic': 'sum'
        }).sort_values('volume', ascending=False).head(5)
    else:
        url_impact = pd.DataFrame()
    
    # Quick wins
    quick_wins = df_filtered[
        (df_filtered.get('meilleure_pos', pd.Series([100]*len(df_filtered))) <= 10) &
        (df_filtered.get('derniere_pos', pd.Series([0]*len(df_filtered))) > 10) &
        (df_filtered.get('volume', pd.Series([0]*len(df_filtered))) >= 100)
    ].nlargest(10, 'volume') if 'meilleure_pos' in df_filtered.columns else pd.DataFrame()
    
    # Top pertes
    top_pertes = df_filtered[df_filtered['diff_pos'] < 0].nlargest(10, 'priority_score')
    
    # KW sortis
    if 'statut' in df_filtered.columns:
        statut_str = df_filtered['statut'].astype(str).str.lower()
        kw_sortis = df_filtered[statut_str.str.contains('sort|out', na=False)].nlargest(10, 'volume')
    else:
        kw_sortis = df_filtered[df_filtered['derniere_pos'] > 100].nlargest(10, 'volume') if 'derniere_pos' in df_filtered.columns else pd.DataFrame()
    
    report = f"""# Rapport d'Analyse SEO â€” {datetime.now().strftime('%d/%m/%Y')}

## ğŸ“Š Situation globale

- **Mots-clÃ©s analysÃ©s** : {kpis['total']:,}
- **En perte** : {kpis['pertes']:,} ({kpis['pct_pertes']:.1f}%)
- **En gain** : {kpis['gains']:,} ({kpis['pct_gains']:.1f}%)
- **Stables** : {kpis['stables']:,} ({kpis['pct_stables']:.1f}%)
- **Sortis des SERPs** : {kpis['sortis']:,}

### Impact business
- **Volume de recherche impactÃ© (pertes)** : {kpis['volume_perdu']:,} recherches/mois
- **Trafic estimÃ© perdu** : {kpis['trafic_perdu']:,} visites/mois
- **Volume gagnÃ©** : {kpis['volume_gagne']:,} recherches/mois

---

## ğŸš¨ Pages critiques (Top 5 URLs impactÃ©es)

"""
    
    if not url_impact.empty:
        for i, (url, row) in enumerate(url_impact.iterrows(), 1):
            report += f"{i}. **{url}**\n   - {int(row['mot_cle'])} KW en perte\n   - Volume impactÃ© : {int(row['volume']):,}\n\n"
    else:
        report += "_DonnÃ©es URL non disponibles_\n\n"
    
    report += """---

## âš¡ Actions prioritaires

### ğŸ”´ Urgence haute â€” Quick wins (rÃ©cupÃ©ration rapide possible)

Ces mots-clÃ©s Ã©taient en top 10 et ont chutÃ©. Le potentiel de rÃ©cupÃ©ration est Ã©levÃ© :

"""
    
    if not quick_wins.empty:
        for _, row in quick_wins.head(5).iterrows():
            mc = row.get('mot_cle', 'N/A')
            vol = int(row.get('volume', 0))
            best = int(row.get('meilleure_pos', 0))
            current = int(row.get('derniere_pos', 0))
            url = row.get('url', 'N/A')
            report += f"- **{mc}** (vol: {vol:,}) : Ã©tait #{best} â†’ maintenant #{current}\n  URL : {url}\n\n"
    else:
        report += "_Aucun quick win identifiÃ© avec les critÃ¨res actuels_\n\n"
    
    report += """
### ğŸŸ  Urgence moyenne â€” Top pertes par impact

Ces mots-clÃ©s reprÃ©sentent les plus grosses pertes pondÃ©rÃ©es (volume Ã— chute Ã— position d'origine) :

"""
    
    if not top_pertes.empty:
        for _, row in top_pertes.head(5).iterrows():
            mc = row.get('mot_cle', 'N/A')
            vol = int(row.get('volume', 0))
            diff = int(row.get('diff_pos', 0))
            url = row.get('url', 'N/A')
            report += f"- **{mc}** (vol: {vol:,}, diff: {diff})\n  URL : {url}\n\n"
    
    report += """
### ğŸŸ¡ Ã€ surveiller â€” Mots-clÃ©s sortis des SERPs

"""
    
    if not kw_sortis.empty:
        for _, row in kw_sortis.head(5).iterrows():
            mc = row.get('mot_cle', 'N/A')
            vol = int(row.get('volume', 0))
            report += f"- **{mc}** (vol: {vol:,})\n"
    else:
        report += "_Aucun mot-clÃ© sorti identifiÃ©_\n"
    
    report += f"""

---

## ğŸ“‹ Recommandations gÃ©nÃ©rales

1. **Prioriser les quick wins** : Ces KW Ã©taient bien positionnÃ©s, une mise Ã  jour du contenu + renforcement du maillage interne peut suffire.

2. **Auditer les pages critiques** : Les {min(5, len(url_impact))} URLs les plus impactÃ©es nÃ©cessitent un audit complet (contenu, technique, backlinks).

3. **Surveiller la concurrence** : VÃ©rifier si les pertes sont dues Ã  des mises Ã  jour algo ou Ã  des concurrents qui ont amÃ©liorÃ© leur contenu.

4. **Planifier les mises Ã  jour** : CrÃ©er un calendrier Ã©ditorial pour retravailler les contenus impactÃ©s par ordre de prioritÃ©.

---

_Rapport gÃ©nÃ©rÃ© automatiquement â€” Haloscan SEO Diff Analyzer_
"""
    
    return report


# =============================================================================
# INTERFACE PRINCIPALE
# =============================================================================

st.title("ğŸ“Š Haloscan SEO Diff Analyzer")
st.markdown("Analyse des diffÃ©rentiels de positions SEO â€¢ ConÃ§u pour fichiers volumineux (250k+ lignes)")

# Sidebar - Upload et filtres
with st.sidebar:
    st.header("ğŸ“ Import des donnÃ©es")
    uploaded_file = st.file_uploader(
        "Charger le fichier CSV Haloscan",
        type=['csv'],
        help="Export Haloscan avec colonnes : mot-clÃ©, url, positions, diff, volume, statut..."
    )
    
    if uploaded_file:
        st.success(f"âœ… Fichier chargÃ© : {uploaded_file.name}")

# Chargement des donnÃ©es
if uploaded_file:
    with st.spinner("â³ Chargement et analyse des donnÃ©es..."):
        df = load_data(uploaded_file)
        
        # Calcul du score de prioritÃ©
        df['priority_score'] = df.apply(calculate_priority_score, axis=1)
        
        # Calcul du potentiel de rÃ©cupÃ©ration si possible
        if 'meilleure_pos' in df.columns:
            df['recovery_potential'] = df.apply(calculate_recovery_potential, axis=1)
        
        st.success(f"âœ… {len(df):,} mots-clÃ©s chargÃ©s")
    
    # Affichage des colonnes dÃ©tectÃ©es
    with st.sidebar:
        with st.expander("ğŸ” Colonnes dÃ©tectÃ©es"):
            st.write(list(df.columns))
    
    # ==========================================================================
    # FILTRES
    # ==========================================================================
    
    with st.sidebar:
        st.header("ğŸ›ï¸ Filtres")
        
        # Filtre par statut
        if 'statut' in df.columns:
            statuts_disponibles = df['statut'].astype(str).dropna().unique().tolist()
            statuts_selectionnes = st.multiselect(
                "Statut",
                options=statuts_disponibles,
                default=statuts_disponibles
            )
        else:
            statuts_selectionnes = None
        
        # Filtre par volume
        if 'volume' in df.columns:
            vol_min, vol_max = int(df['volume'].min() or 0), int(df['volume'].max() or 10000)
            volume_range = st.slider(
                "Volume de recherche",
                min_value=vol_min,
                max_value=vol_max,
                value=(vol_min, vol_max)
            )
        else:
            volume_range = None
        
        # Filtre par diff
        if 'diff_pos' in df.columns:
            diff_min, diff_max = int(df['diff_pos'].min() or -100), int(df['diff_pos'].max() or 100)
            diff_range = st.slider(
                "DiffÃ©rentiel de position",
                min_value=diff_min,
                max_value=diff_max,
                value=(diff_min, diff_max)
            )
        else:
            diff_range = None
        
        # Filtre par position
        if 'derniere_pos' in df.columns:
            position_filter = st.selectbox(
                "Tranche de position actuelle",
                options=['Toutes', 'Top 3', 'Top 10', 'Top 20', 'Page 2 (11-20)', 'Page 3+ (21+)']
            )
        else:
            position_filter = 'Toutes'
        
        # Recherche textuelle
        search_kw = st.text_input("ğŸ” Rechercher un mot-clÃ©", "")
        search_url = st.text_input("ğŸ” Filtrer par URL (contient)", "")
    
    # Application des filtres
    df_filtered = df.copy()
    
    if statuts_selectionnes is not None and 'statut' in df_filtered.columns:
        df_filtered = df_filtered[df_filtered['statut'].isin(statuts_selectionnes)]
    
    if volume_range and 'volume' in df_filtered.columns:
        df_filtered = df_filtered[
            (df_filtered['volume'] >= volume_range[0]) & 
            (df_filtered['volume'] <= volume_range[1])
        ]
    
    if diff_range and 'diff_pos' in df_filtered.columns:
        df_filtered = df_filtered[
            (df_filtered['diff_pos'] >= diff_range[0]) & 
            (df_filtered['diff_pos'] <= diff_range[1])
        ]
    
    if position_filter != 'Toutes' and 'derniere_pos' in df_filtered.columns:
        if position_filter == 'Top 3':
            df_filtered = df_filtered[df_filtered['derniere_pos'] <= 3]
        elif position_filter == 'Top 10':
            df_filtered = df_filtered[df_filtered['derniere_pos'] <= 10]
        elif position_filter == 'Top 20':
            df_filtered = df_filtered[df_filtered['derniere_pos'] <= 20]
        elif position_filter == 'Page 2 (11-20)':
            df_filtered = df_filtered[(df_filtered['derniere_pos'] >= 11) & (df_filtered['derniere_pos'] <= 20)]
        elif position_filter == 'Page 3+ (21+)':
            df_filtered = df_filtered[df_filtered['derniere_pos'] >= 21]
    
    if search_kw and 'mot_cle' in df_filtered.columns:
        df_filtered = df_filtered[df_filtered['mot_cle'].str.contains(search_kw, case=False, na=False)]
    
    if search_url and 'url' in df_filtered.columns:
        df_filtered = df_filtered[df_filtered['url'].str.contains(search_url, case=False, na=False)]
    
    # ==========================================================================
    # CALCUL DES KPIs
    # ==========================================================================
    
    total_kw = len(df_filtered)
    
    # DÃ©tection des pertes/gains selon la colonne disponible
    if 'statut' in df_filtered.columns:
        # Conversion en string pour Ã©viter les erreurs sur colonnes mixtes
        statut_str = df_filtered['statut'].astype(str).str.lower()
        pertes = len(df_filtered[statut_str.str.contains('perd|lost|down', na=False)])
        gains = len(df_filtered[statut_str.str.contains('gagn|gain|up', na=False)])
        stables = len(df_filtered[statut_str.str.contains('stable', na=False)])
        sortis = len(df_filtered[statut_str.str.contains('sort|out', na=False)])
    elif 'diff_pos' in df_filtered.columns:
        pertes = len(df_filtered[df_filtered['diff_pos'] < 0])
        gains = len(df_filtered[df_filtered['diff_pos'] > 0])
        stables = len(df_filtered[df_filtered['diff_pos'] == 0])
        sortis = len(df_filtered[df_filtered['derniere_pos'] > 100]) if 'derniere_pos' in df_filtered.columns else 0
    else:
        pertes = gains = stables = sortis = 0
    
    # Calculs de volume/trafic
    if 'volume' in df_filtered.columns and 'diff_pos' in df_filtered.columns:
        volume_perdu = int(df_filtered[df_filtered['diff_pos'] < 0]['volume'].sum())
        volume_gagne = int(df_filtered[df_filtered['diff_pos'] > 0]['volume'].sum())
    else:
        volume_perdu = volume_gagne = 0
    
    if 'trafic' in df_filtered.columns and 'diff_pos' in df_filtered.columns:
        trafic_perdu = int(df_filtered[df_filtered['diff_pos'] < 0]['trafic'].sum())
        trafic_gagne = int(df_filtered[df_filtered['diff_pos'] > 0]['trafic'].sum())
    else:
        trafic_perdu = trafic_gagne = 0
    
    kpis = {
        'total': total_kw,
        'pertes': pertes,
        'gains': gains,
        'stables': stables,
        'sortis': sortis,
        'pct_pertes': (pertes / total_kw * 100) if total_kw > 0 else 0,
        'pct_gains': (gains / total_kw * 100) if total_kw > 0 else 0,
        'pct_stables': (stables / total_kw * 100) if total_kw > 0 else 0,
        'volume_perdu': volume_perdu,
        'volume_gagne': volume_gagne,
        'trafic_perdu': trafic_perdu,
        'trafic_gagne': trafic_gagne
    }
    
    # ==========================================================================
    # ONGLETS
    # ==========================================================================
    
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“Š Dashboard",
        "ğŸ”´ Pertes critiques",
        "ğŸ“ Par URL",
        "âš¡ Quick wins",
        "âŒ Sortis",
        "ğŸŸ¢ Gains",
        "ğŸ“ Rapport"
    ])
    
    # ==========================================================================
    # TAB 1 : DASHBOARD
    # ==========================================================================
    
    with tab1:
        st.header("Vue d'ensemble")
        
        # KPIs principaux
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("Total KW", f"{total_kw:,}")
        with col2:
            st.metric("ğŸ”´ Pertes", f"{pertes:,}", f"{kpis['pct_pertes']:.1f}%")
        with col3:
            st.metric("ğŸŸ¢ Gains", f"{gains:,}", f"{kpis['pct_gains']:.1f}%")
        with col4:
            st.metric("âšª Stables", f"{stables:,}", f"{kpis['pct_stables']:.1f}%")
        with col5:
            st.metric("ğŸŸ  Sortis", f"{sortis:,}")
        
        st.divider()
        
        # Impact business
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“‰ Volume perdu", f"{volume_perdu:,}")
        with col2:
            st.metric("ğŸ“ˆ Volume gagnÃ©", f"{volume_gagne:,}")
        with col3:
            st.metric("ğŸš« Trafic perdu", f"{trafic_perdu:,}")
        with col4:
            st.metric("âœ… Trafic gagnÃ©", f"{trafic_gagne:,}")
        
        st.divider()
        
        # Graphiques
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("RÃ©partition par statut")
            if 'statut' in df_filtered.columns:
                statut_counts = df_filtered['statut'].astype(str).value_counts()
                fig_pie = px.pie(
                    values=statut_counts.values,
                    names=statut_counts.index,
                    color_discrete_sequence=px.colors.qualitative.Set2
                )
                fig_pie.update_layout(height=350)
                st.plotly_chart(fig_pie, use_container_width=True)
            else:
                # Pie chart basÃ© sur diff_pos
                labels = ['Pertes', 'Gains', 'Stables']
                values = [pertes, gains, stables]
                fig_pie = px.pie(values=values, names=labels, color_discrete_sequence=['#EF4444', '#22C55E', '#6B7280'])
                fig_pie.update_layout(height=350)
                st.plotly_chart(fig_pie, use_container_width=True)
        
        with col2:
            st.subheader("Distribution des diffÃ©rentiels")
            if 'diff_pos' in df_filtered.columns:
                fig_hist = px.histogram(
                    df_filtered,
                    x='diff_pos',
                    nbins=50,
                    color_discrete_sequence=['#667eea']
                )
                fig_hist.update_layout(
                    xaxis_title="DiffÃ©rentiel de position",
                    yaxis_title="Nombre de KW",
                    height=350
                )
                st.plotly_chart(fig_hist, use_container_width=True)
        
        # Top URLs impactÃ©es
        if 'url' in df_filtered.columns and 'volume' in df_filtered.columns:
            st.subheader("Top 10 URLs les plus impactÃ©es (en volume perdu)")
            url_impact = df_filtered[df_filtered['diff_pos'] < 0].groupby('url').agg({
                'mot_cle': 'count',
                'volume': 'sum'
            }).rename(columns={'mot_cle': 'nb_kw_perdus', 'volume': 'volume_impacte'})
            url_impact = url_impact.sort_values('volume_impacte', ascending=False).head(10)
            
            fig_bar = px.bar(
                url_impact.reset_index(),
                x='volume_impacte',
                y='url',
                orientation='h',
                color_discrete_sequence=['#EF4444']
            )
            fig_bar.update_layout(yaxis={'categoryorder': 'total ascending'}, height=400)
            st.plotly_chart(fig_bar, use_container_width=True)
    
    # ==========================================================================
    # TAB 2 : PERTES CRITIQUES
    # ==========================================================================
    
    with tab2:
        st.header("ğŸ”´ Pertes critiques")
        st.markdown("Mots-clÃ©s triÃ©s par **score de prioritÃ©** (volume Ã— diff Ã— facteur position)")
        
        df_pertes = df_filtered[df_filtered['diff_pos'] < 0].sort_values('priority_score', ascending=False)
        
        st.info(f"**{len(df_pertes):,}** mots-clÃ©s en perte de position")
        
        # Colonnes Ã  afficher
        cols_display = ['mot_cle', 'url', 'ancienne_pos', 'derniere_pos', 'diff_pos', 'volume', 'trafic', 'priority_score']
        cols_display = [c for c in cols_display if c in df_pertes.columns]
        
        st.dataframe(
            df_pertes[cols_display].head(500),
            use_container_width=True,
            height=600
        )
        
        # Export
        csv_pertes = df_pertes[cols_display].to_csv(index=False, sep=';').encode('utf-8')
        st.download_button(
            "ğŸ“¥ Exporter les pertes critiques (CSV)",
            csv_pertes,
            "pertes_critiques.csv",
            "text/csv"
        )
    
    # ==========================================================================
    # TAB 3 : PAR URL
    # ==========================================================================
    
    with tab3:
        st.header("ğŸ“ Analyse par URL")
        
        if 'url' in df_filtered.columns:
            # AgrÃ©gation par URL
            url_stats = df_filtered.groupby('url').agg({
                'mot_cle': 'count',
                'diff_pos': ['sum', 'mean'],
                'volume': 'sum',
                'trafic': 'sum',
                'priority_score': 'sum'
            }).reset_index()
            
            url_stats.columns = ['url', 'total_kw', 'diff_total', 'diff_moyen', 'volume_total', 'trafic_total', 'score_priorite']
            
            # KW en perte par URL
            pertes_par_url = df_filtered[df_filtered['diff_pos'] < 0].groupby('url').size().reset_index(name='kw_en_perte')
            url_stats = url_stats.merge(pertes_par_url, on='url', how='left')
            url_stats['kw_en_perte'] = url_stats['kw_en_perte'].fillna(0).astype(int)
            
            # Score de santÃ©
            url_stats['sante_pct'] = ((url_stats['total_kw'] - url_stats['kw_en_perte']) / url_stats['total_kw'] * 100).round(1)
            
            url_stats = url_stats.sort_values('score_priorite', ascending=False)
            
            st.info(f"**{len(url_stats):,}** URLs analysÃ©es")
            
            st.dataframe(
                url_stats.head(200),
                use_container_width=True,
                height=500
            )
            
            # DÃ©tail d'une URL
            st.subheader("ğŸ” DÃ©tail d'une URL")
            url_selectionnee = st.selectbox("SÃ©lectionner une URL", url_stats['url'].head(100).tolist())
            
            if url_selectionnee:
                df_url = df_filtered[df_filtered['url'] == url_selectionnee]
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("KW total", len(df_url))
                with col2:
                    st.metric("KW en perte", len(df_url[df_url['diff_pos'] < 0]))
                with col3:
                    st.metric("Volume total", f"{int(df_url['volume'].sum()):,}")
                
                cols_url = ['mot_cle', 'ancienne_pos', 'derniere_pos', 'diff_pos', 'volume', 'statut']
                cols_url = [c for c in cols_url if c in df_url.columns]
                st.dataframe(df_url[cols_url], use_container_width=True)
        else:
            st.warning("Colonne 'url' non dÃ©tectÃ©e dans le fichier")
    
    # ==========================================================================
    # TAB 4 : QUICK WINS
    # ==========================================================================
    
    with tab4:
        st.header("âš¡ Quick wins â€” OpportunitÃ©s de rÃ©cupÃ©ration")
        st.markdown("KW qui Ã©taient **top 10**, ont chutÃ©, mais ont un **potentiel de rÃ©cupÃ©ration**")
        
        if 'meilleure_pos' in df_filtered.columns and 'derniere_pos' in df_filtered.columns:
            df_quickwins = df_filtered[
                (df_filtered['meilleure_pos'] <= 10) &
                (df_filtered['derniere_pos'] > 10) &
                (df_filtered['volume'] >= 100)
            ].copy()
            
            df_quickwins = df_quickwins.sort_values('recovery_potential', ascending=False)
            
            st.success(f"**{len(df_quickwins):,}** opportunitÃ©s de rÃ©cupÃ©ration identifiÃ©es")
            
            cols_qw = ['mot_cle', 'url', 'meilleure_pos', 'derniere_pos', 'diff_pos', 'volume', 'recovery_potential']
            cols_qw = [c for c in cols_qw if c in df_quickwins.columns]
            
            st.dataframe(
                df_quickwins[cols_qw].head(500),
                use_container_width=True,
                height=600
            )
            
            csv_qw = df_quickwins[cols_qw].to_csv(index=False, sep=';').encode('utf-8')
            st.download_button(
                "ğŸ“¥ Exporter les quick wins (CSV)",
                csv_qw,
                "quick_wins.csv",
                "text/csv"
            )
        else:
            st.warning("Colonnes 'meilleure_pos' et/ou 'derniere_pos' non dÃ©tectÃ©es")
    
    # ==========================================================================
    # TAB 5 : SORTIS
    # ==========================================================================
    
    with tab5:
        st.header("âŒ Mots-clÃ©s sortis des SERPs")
        
        if 'statut' in df_filtered.columns:
            statut_str = df_filtered['statut'].astype(str).str.lower()
            df_sortis = df_filtered[statut_str.str.contains('sort|out', na=False)]
        elif 'derniere_pos' in df_filtered.columns:
            df_sortis = df_filtered[df_filtered['derniere_pos'] > 100]
        else:
            df_sortis = pd.DataFrame()
        
        if not df_sortis.empty:
            df_sortis = df_sortis.sort_values('volume', ascending=False)
            
            st.warning(f"**{len(df_sortis):,}** mots-clÃ©s ont disparu des SERPs")
            
            cols_sortis = ['mot_cle', 'url', 'ancienne_pos', 'volume', 'trafic']
            cols_sortis = [c for c in cols_sortis if c in df_sortis.columns]
            
            st.dataframe(
                df_sortis[cols_sortis].head(500),
                use_container_width=True,
                height=600
            )
            
            csv_sortis = df_sortis[cols_sortis].to_csv(index=False, sep=';').encode('utf-8')
            st.download_button(
                "ğŸ“¥ Exporter les KW sortis (CSV)",
                csv_sortis,
                "kw_sortis.csv",
                "text/csv"
            )
        else:
            st.info("Aucun mot-clÃ© sorti dÃ©tectÃ©")
    
    # ==========================================================================
    # TAB 6 : GAINS
    # ==========================================================================
    
    with tab6:
        st.header("ğŸŸ¢ Gains de position")
        
        df_gains = df_filtered[df_filtered['diff_pos'] > 0].sort_values('priority_score', ascending=False)
        
        st.success(f"**{len(df_gains):,}** mots-clÃ©s en progression")
        
        cols_gains = ['mot_cle', 'url', 'ancienne_pos', 'derniere_pos', 'diff_pos', 'volume', 'trafic']
        cols_gains = [c for c in cols_gains if c in df_gains.columns]
        
        st.dataframe(
            df_gains[cols_gains].head(500),
            use_container_width=True,
            height=600
        )
    
    # ==========================================================================
    # TAB 7 : RAPPORT
    # ==========================================================================
    
    with tab7:
        st.header("ğŸ“ Rapport pour l'Ã©quipe contenu")
        
        if st.button("ğŸ”„ GÃ©nÃ©rer le rapport", type="primary"):
            with st.spinner("GÃ©nÃ©ration du rapport..."):
                report = generate_report(df, df_filtered, kpis)
                st.session_state['report'] = report
        
        if 'report' in st.session_state:
            st.markdown(st.session_state['report'])
            
            st.divider()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.download_button(
                    "ğŸ“¥ TÃ©lÃ©charger en Markdown",
                    st.session_state['report'],
                    "rapport_seo.md",
                    "text/markdown"
                )
            
            with col2:
                st.code(st.session_state['report'], language='markdown')

else:
    # Ã‰tat initial - pas de fichier chargÃ©
    st.info("ğŸ‘† Charge un fichier CSV Haloscan dans la sidebar pour commencer l'analyse")
    
    st.markdown("""
    ### ğŸ“‹ Format attendu
    
    Le fichier doit contenir au minimum ces colonnes :
    - `mot-clÃ© (mc)` ou `keyword` â€” le mot-clÃ© trackÃ©
    - `url` â€” l'URL positionnÃ©e
    - `diff_pos` â€” diffÃ©rentiel de position (nÃ©gatif = perte)
    - `volume` â€” volume de recherche mensuel
    
    Colonnes optionnelles mais recommandÃ©es :
    - `derniÃ¨re_pos` â€” position actuelle
    - `vieille_pos` / `ancienne_pos` â€” position de la pÃ©riode prÃ©cÃ©dente
    - `meilleure_pos` â€” meilleure position historique
    - `statut` â€” perdu, gagnÃ©, stable, sorti...
    - `trafic` â€” estimation du trafic
    
    ### ğŸš€ CapacitÃ©
    
    L'outil peut traiter des fichiers jusqu'Ã  **300 000+ lignes** sans problÃ¨me.
    """)
