"""
Haloscan SEO Diff Analyzer
Analyse des diff√©rentiels de positions SEO entre deux p√©riodes
Con√ßu pour traiter des fichiers volumineux (250k+ lignes)
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
from datetime import datetime

# Configuration de la page
st.set_page_config(
    page_title="Haloscan SEO Diff Analyzer",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 0.5rem;
        color: white;
    }
    .loss { color: #EF4444; }
    .gain { color: #22C55E; }
    .stable { color: #6B7280; }
    .out { color: #F97316; }
    .stMetric > div {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_data
def load_data(uploaded_file):
    """Charge et parse le fichier CSV avec d√©tection automatique du s√©parateur"""
    try:
        # Essai avec point-virgule d'abord (format Haloscan habituel)
        df = pd.read_csv(uploaded_file, sep=';', encoding='utf-8')
        if len(df.columns) < 5:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, sep=',', encoding='utf-8')
    except UnicodeDecodeError:
        uploaded_file.seek(0)
        try:
            df = pd.read_csv(uploaded_file, sep=';', encoding='latin-1')
            if len(df.columns) < 5:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, sep=',', encoding='latin-1')
        except:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, sep=';', encoding='cp1252')
    
    # Normalisation des noms de colonnes
    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')
    
    # Renommage des colonnes courantes Haloscan
    column_mapping = {
        'mot-cl√©_(mc)': 'mot_cle',
        'mot-cl√©': 'mot_cle',
        'mot_cl√©_(mc)': 'mot_cle',
        'mot_cle_(mc)': 'mot_cle',
        'mc': 'mot_cle',
        'keyword': 'mot_cle',
        'derni√®re_pos': 'derniere_pos',
        'derniere_pos': 'derniere_pos',
        'derni√£re_pos': 'derniere_pos',
        'position': 'derniere_pos',
        'vieille_pos': 'ancienne_pos',
        'plus_vieille_pos': 'ancienne_pos',
        'old_pos': 'ancienne_pos',
        'meilleure_pos': 'meilleure_pos',
        'best_pos': 'meilleure_pos',
        'pos_perdues': 'pos_perdues',
        'diff_pos': 'diff_pos',
        'diff': 'diff_pos',
        'volume': 'volume',
        'vol': 'volume',
        'volumeh': 'volumeh',
        'statut': 'statut',
        'status': 'statut',
        'trafic': 'trafic',
        'traffic': 'trafic',
        'url': 'url',
        'cpc': 'cpc',
        'comp': 'competition',
        'competition': 'competition'
    }
    
    df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})
    
    # Conversion des colonnes num√©riques
    numeric_cols = ['derniere_pos', 'ancienne_pos', 'meilleure_pos', 'diff_pos', 'pos_perdues', 'volume', 'volumeh', 'trafic', 'cpc']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    return df


def calculate_priority_score(row):
    """Calcule le score de priorit√© pour un mot-cl√©"""
    volume = row.get('volume', 0) or 0
    diff = abs(row.get('diff_pos', 0) or 0)
    ancienne_pos = row.get('ancienne_pos', 100) or 100
    
    # Facteur de position : plus on √©tait haut, plus c'est grave de perdre
    if ancienne_pos <= 3:
        facteur = 3
    elif ancienne_pos <= 10:
        facteur = 2
    elif ancienne_pos <= 20:
        facteur = 1.5
    else:
        facteur = 1
    
    return volume * diff * facteur


def calculate_recovery_potential(row):
    """Calcule le potentiel de r√©cup√©ration"""
    volume = row.get('volume', 0) or 0
    meilleure_pos = row.get('meilleure_pos', 100) or 100
    if meilleure_pos == 0:
        meilleure_pos = 1
    return volume / meilleure_pos


def get_status_color(statut):
    """Retourne la couleur associ√©e au statut"""
    statut = str(statut).lower()
    if 'perd' in statut or 'lost' in statut or 'down' in statut:
        return '#EF4444'
    elif 'gagn' in statut or 'gain' in statut or 'up' in statut:
        return '#22C55E'
    elif 'stable' in statut:
        return '#6B7280'
    elif 'sort' in statut or 'out' in statut:
        return '#F97316'
    elif 'nouveau' in statut or 'new' in statut:
        return '#3B82F6'
    return '#6B7280'


def generate_report(df, df_filtered, kpis):
    """G√©n√®re le rapport textuel pour l'√©quipe contenu"""
    
    # Top 5 URLs impact√©es
    if 'url' in df_filtered.columns:
        url_impact = df_filtered[df_filtered['diff_pos'] < 0].groupby('url').agg({
            'mot_cle': 'count',
            'volume': 'sum',
            'trafic': 'sum'
        }).sort_values('volume', ascending=False).head(5)
    else:
        url_impact = pd.DataFrame()
    
    # Quick wins
    quick_wins = df_filtered[
        (df_filtered.get('meilleure_pos', pd.Series([100]*len(df_filtered))) <= 10) &
        (df_filtered.get('derniere_pos', pd.Series([0]*len(df_filtered))) > 10) &
        (df_filtered.get('volume', pd.Series([0]*len(df_filtered))) >= 100)
    ].nlargest(10, 'volume') if 'meilleure_pos' in df_filtered.columns else pd.DataFrame()
    
    # Top pertes
    top_pertes = df_filtered[df_filtered['diff_pos'] < 0].nlargest(10, 'priority_score')
    
    # KW sortis (position > 100 ou disparu)
    if 'derniere_pos' in df_filtered.columns:
        kw_sortis = df_filtered[(df_filtered['derniere_pos'] > 100) | (df_filtered['derniere_pos'].isna())]
        if 'volume' in kw_sortis.columns and len(kw_sortis) > 0:
            kw_sortis = kw_sortis.nlargest(10, 'volume')
    else:
        kw_sortis = pd.DataFrame()
    
    report = f"""# Rapport d'Analyse SEO ‚Äî {datetime.now().strftime('%d/%m/%Y')}

## üìä Situation globale

- **Mots-cl√©s analys√©s** : {kpis['total']:,}
- **En perte** : {kpis['pertes']:,} ({kpis['pct_pertes']:.1f}%)
- **En gain** : {kpis['gains']:,} ({kpis['pct_gains']:.1f}%)
- **Stables** : {kpis['stables']:,} ({kpis['pct_stables']:.1f}%)
- **Sortis des SERPs** : {kpis['sortis']:,}

### Impact business
- **Volume de recherche impact√© (pertes)** : {kpis['volume_perdu']:,} recherches/mois
- **Trafic estim√© perdu** : {kpis['trafic_perdu']:,} visites/mois
- **Volume gagn√©** : {kpis['volume_gagne']:,} recherches/mois

---

## üö® Pages critiques (Top 5 URLs impact√©es)

"""
    
    if not url_impact.empty:
        for i, (url, row) in enumerate(url_impact.iterrows(), 1):
            report += f"{i}. **{url}**\n   - {int(row['mot_cle'])} KW en perte\n   - Volume impact√© : {int(row['volume']):,}\n\n"
    else:
        report += "_Donn√©es URL non disponibles_\n\n"
    
    report += """---

## ‚ö° Actions prioritaires

### üî¥ Urgence haute ‚Äî Quick wins (r√©cup√©ration rapide possible)

Ces mots-cl√©s √©taient en top 10 et ont chut√©. Le potentiel de r√©cup√©ration est √©lev√© :

"""
    
    if not quick_wins.empty:
        for _, row in quick_wins.head(5).iterrows():
            mc = row.get('mot_cle', 'N/A')
            vol = int(row.get('volume', 0))
            best = int(row.get('meilleure_pos', 0))
            current = int(row.get('derniere_pos', 0))
            url = row.get('url', 'N/A')
            report += f"- **{mc}** (vol: {vol:,}) : √©tait #{best} ‚Üí maintenant #{current}\n  URL : {url}\n\n"
    else:
        report += "_Aucun quick win identifi√© avec les crit√®res actuels_\n\n"
    
    report += """
### üü† Urgence moyenne ‚Äî Top pertes par impact

Ces mots-cl√©s repr√©sentent les plus grosses pertes pond√©r√©es (volume √ó chute √ó position d'origine) :

"""
    
    if not top_pertes.empty:
        for _, row in top_pertes.head(5).iterrows():
            mc = row.get('mot_cle', 'N/A')
            vol = int(row.get('volume', 0))
            diff = int(row.get('diff_pos', 0))
            url = row.get('url', 'N/A')
            report += f"- **{mc}** (vol: {vol:,}, diff: {diff})\n  URL : {url}\n\n"
    
    report += """
### üü° √Ä surveiller ‚Äî Mots-cl√©s sortis des SERPs

"""
    
    if not kw_sortis.empty:
        for _, row in kw_sortis.head(5).iterrows():
            mc = row.get('mot_cle', 'N/A')
            vol = int(row.get('volume', 0))
            report += f"- **{mc}** (vol: {vol:,})\n"
    else:
        report += "_Aucun mot-cl√© sorti identifi√©_\n"
    
    report += f"""

---

## üìã Recommandations g√©n√©rales

1. **Prioriser les quick wins** : Ces KW √©taient bien positionn√©s, une mise √† jour du contenu + renforcement du maillage interne peut suffire.

2. **Auditer les pages critiques** : Les {min(5, len(url_impact))} URLs les plus impact√©es n√©cessitent un audit complet (contenu, technique, backlinks).

3. **Surveiller la concurrence** : V√©rifier si les pertes sont dues √† des mises √† jour algo ou √† des concurrents qui ont am√©lior√© leur contenu.

4. **Planifier les mises √† jour** : Cr√©er un calendrier √©ditorial pour retravailler les contenus impact√©s par ordre de priorit√©.

---

_Rapport g√©n√©r√© automatiquement ‚Äî Haloscan SEO Diff Analyzer_
"""
    
    return report


# =============================================================================
# INTERFACE PRINCIPALE
# =============================================================================

st.title("üìä Haloscan SEO Diff Analyzer")
st.markdown("Analyse des diff√©rentiels de positions SEO ‚Ä¢ Con√ßu pour fichiers volumineux (250k+ lignes)")

# Sidebar - Upload et filtres
with st.sidebar:
    st.header("üìÅ Import des donn√©es")
    uploaded_file = st.file_uploader(
        "Charger le fichier CSV Haloscan",
        type=['csv'],
        help="Export Haloscan avec colonnes : mot-cl√©, url, positions, diff, volume, statut..."
    )
    
    if uploaded_file:
        st.success(f"‚úÖ Fichier charg√© : {uploaded_file.name}")

# Chargement des donn√©es
if uploaded_file:
    with st.spinner("‚è≥ Chargement et analyse des donn√©es..."):
        df = load_data(uploaded_file)
        
        # Calcul du score de priorit√©
        df['priority_score'] = df.apply(calculate_priority_score, axis=1)
        
        # Calcul du potentiel de r√©cup√©ration si possible
        if 'meilleure_pos' in df.columns:
            df['recovery_potential'] = df.apply(calculate_recovery_potential, axis=1)
        
        st.success(f"‚úÖ {len(df):,} mots-cl√©s charg√©s")
    
    # Affichage des colonnes d√©tect√©es
    with st.sidebar:
        with st.expander("üîç Colonnes d√©tect√©es"):
            st.write(list(df.columns))
    
    # ==========================================================================
    # FILTRES
    # ==========================================================================
    
    with st.sidebar:
        st.header("üéõÔ∏è Filtres")
        
        # Filtre par type de variation
        variation_filter = st.multiselect(
            "Type de variation",
            options=['Pertes', 'Gains', 'Stables'],
            default=['Pertes', 'Gains', 'Stables']
        )
        
        # Filtre par volume
        if 'volume' in df.columns:
            vol_min, vol_max = int(df['volume'].min() or 0), int(df['volume'].max() or 10000)
            volume_range = st.slider(
                "Volume de recherche",
                min_value=vol_min,
                max_value=vol_max,
                value=(vol_min, vol_max)
            )
        else:
            volume_range = None
        
        # Filtre par diff
        if 'diff_pos' in df.columns:
            diff_min, diff_max = int(df['diff_pos'].min() or -100), int(df['diff_pos'].max() or 100)
            diff_range = st.slider(
                "Diff√©rentiel de position",
                min_value=diff_min,
                max_value=diff_max,
                value=(diff_min, diff_max)
            )
        else:
            diff_range = None
        
        # Filtre par position
        if 'derniere_pos' in df.columns:
            position_filter = st.selectbox(
                "Tranche de position actuelle",
                options=['Toutes', 'Top 3', 'Top 10', 'Top 20', 'Page 2 (11-20)', 'Page 3+ (21+)']
            )
        else:
            position_filter = 'Toutes'
        
        # Recherche textuelle
        search_kw = st.text_input("üîé Rechercher un mot-cl√©", "")
        search_url = st.text_input("üîé Filtrer par URL (contient)", "")
    
    # Application des filtres
    df_filtered = df.copy()
    
    # Filtre par type de variation
    if 'diff_pos' in df_filtered.columns:
        conditions = []
        if 'Pertes' in variation_filter:
            conditions.append(df_filtered['diff_pos'] < 0)
        if 'Gains' in variation_filter:
            conditions.append(df_filtered['diff_pos'] > 0)
        if 'Stables' in variation_filter:
            conditions.append(df_filtered['diff_pos'] == 0)
        if conditions:
            combined_condition = conditions[0]
            for cond in conditions[1:]:
                combined_condition = combined_condition | cond
            df_filtered = df_filtered[combined_condition]
    
    if volume_range and 'volume' in df_filtered.columns:
        df_filtered = df_filtered[
            (df_filtered['volume'] >= volume_range[0]) & 
            (df_filtered['volume'] <= volume_range[1])
        ]
    
    if diff_range and 'diff_pos' in df_filtered.columns:
        df_filtered = df_filtered[
            (df_filtered['diff_pos'] >= diff_range[0]) & 
            (df_filtered['diff_pos'] <= diff_range[1])
        ]
    
    if position_filter != 'Toutes' and 'derniere_pos' in df_filtered.columns:
        if position_filter == 'Top 3':
            df_filtered = df_filtered[df_filtered['derniere_pos'] <= 3]
        elif position_filter == 'Top 10':
            df_filtered = df_filtered[df_filtered['derniere_pos'] <= 10]
        elif position_filter == 'Top 20':
            df_filtered = df_filtered[df_filtered['derniere_pos'] <= 20]
        elif position_filter == 'Page 2 (11-20)':
            df_filtered = df_filtered[(df_filtered['derniere_pos'] >= 11) & (df_filtered['derniere_pos'] <= 20)]
        elif position_filter == 'Page 3+ (21+)':
            df_filtered = df_filtered[df_filtered['derniere_pos'] >= 21]
    
    if search_kw and 'mot_cle' in df_filtered.columns:
        df_filtered = df_filtered[df_filtered['mot_cle'].str.contains(search_kw, case=False, na=False)]
    
    if search_url and 'url' in df_filtered.columns:
        df_filtered = df_filtered[df_filtered['url'].str.contains(search_url, case=False, na=False)]
    
    # ==========================================================================
    # CALCUL DES KPIs
    # ==========================================================================
    
    total_kw = len(df_filtered)
    
    # D√©tection des pertes/gains bas√©e sur diff_pos (plus fiable que statut)
    if 'diff_pos' in df_filtered.columns:
        pertes = len(df_filtered[df_filtered['diff_pos'] < 0])
        gains = len(df_filtered[df_filtered['diff_pos'] > 0])
        stables = len(df_filtered[df_filtered['diff_pos'] == 0])
        # Sortis = position actuelle > 100 ou vide/NaN
        if 'derniere_pos' in df_filtered.columns:
            sortis = len(df_filtered[(df_filtered['derniere_pos'] > 100) | (df_filtered['derniere_pos'].isna())])
        else:
            sortis = 0
    else:
        pertes = gains = stables = sortis = 0
    
    # Calculs de volume/trafic (avec gestion des NaN)
    if 'volume' in df_filtered.columns and 'diff_pos' in df_filtered.columns:
        volume_perdu = int(df_filtered[df_filtered['diff_pos'] < 0]['volume'].fillna(0).sum())
        volume_gagne = int(df_filtered[df_filtered['diff_pos'] > 0]['volume'].fillna(0).sum())
    else:
        volume_perdu = volume_gagne = 0
    
    if 'trafic' in df_filtered.columns and 'diff_pos' in df_filtered.columns:
        trafic_perdu = int(df_filtered[df_filtered['diff_pos'] < 0]['trafic'].fillna(0).sum())
        trafic_gagne = int(df_filtered[df_filtered['diff_pos'] > 0]['trafic'].fillna(0).sum())
    else:
        trafic_perdu = trafic_gagne = 0
    
    kpis = {
        'total': total_kw,
        'pertes': pertes,
        'gains': gains,
        'stables': stables,
        'sortis': sortis,
        'pct_pertes': (pertes / total_kw * 100) if total_kw > 0 else 0,
        'pct_gains': (gains / total_kw * 100) if total_kw > 0 else 0,
        'pct_stables': (stables / total_kw * 100) if total_kw > 0 else 0,
        'volume_perdu': volume_perdu,
        'volume_gagne': volume_gagne,
        'trafic_perdu': trafic_perdu,
        'trafic_gagne': trafic_gagne
    }
    
    # ==========================================================================
    # ONGLETS
    # ==========================================================================
    
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "üìä Dashboard",
        "üî¥ Pertes critiques",
        "üìÅ Par URL",
        "‚ö° Quick wins",
        "‚ùå Sortis",
        "üü¢ Gains",
        "üìù Rapport"
    ])
    
    # ==========================================================================
    # TAB 1 : DASHBOARD
    # ==========================================================================
    
    with tab1:
        st.header("Vue d'ensemble")
        
        # KPIs principaux
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("Total KW", f"{total_kw:,}")
        with col2:
            st.metric("üî¥ Pertes", f"{pertes:,}", f"{kpis['pct_pertes']:.1f}%")
        with col3:
            st.metric("üü¢ Gains", f"{gains:,}", f"{kpis['pct_gains']:.1f}%")
        with col4:
            st.metric("‚ö™ Stables", f"{stables:,}", f"{kpis['pct_stables']:.1f}%")
        with col5:
            st.metric("üü† Sortis", f"{sortis:,}")
        
        st.divider()
        
        # Impact business
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üìâ Volume perdu", f"{volume_perdu:,}")
        with col2:
            st.metric("üìà Volume gagn√©", f"{volume_gagne:,}")
        with col3:
            st.metric("üö´ Trafic perdu", f"{trafic_perdu:,}")
        with col4:
            st.metric("‚úÖ Trafic gagn√©", f"{trafic_gagne:,}")
        
        st.divider()
        
        # Graphiques
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("R√©partition par statut")
            # Pie chart bas√© sur diff_pos (pertes/gains/stables)
            labels = ['Pertes', 'Gains', 'Stables', 'Sortis']
            values = [pertes, gains, stables, sortis]
            colors = ['#EF4444', '#22C55E', '#6B7280', '#F97316']
            fig_pie = px.pie(values=values, names=labels, color_discrete_sequence=colors)
            fig_pie.update_layout(height=350)
            st.plotly_chart(fig_pie, use_container_width=True)
        
        with col2:
            st.subheader("Distribution des diff√©rentiels")
            if 'diff_pos' in df_filtered.columns:
                fig_hist = px.histogram(
                    df_filtered,
                    x='diff_pos',
                    nbins=50,
                    color_discrete_sequence=['#667eea']
                )
                fig_hist.update_layout(
                    xaxis_title="Diff√©rentiel de position",
                    yaxis_title="Nombre de KW",
                    height=350
                )
                st.plotly_chart(fig_hist, use_container_width=True)
        
        # Top URLs impact√©es
        if 'url' in df_filtered.columns and 'volume' in df_filtered.columns:
            st.subheader("Top 10 URLs les plus impact√©es (en volume perdu)")
            url_impact = df_filtered[df_filtered['diff_pos'] < 0].groupby('url').agg({
                'mot_cle': 'count',
                'volume': 'sum'
            }).rename(columns={'mot_cle': 'nb_kw_perdus', 'volume': 'volume_impacte'})
            url_impact = url_impact.sort_values('volume_impacte', ascending=False).head(10)
            
            fig_bar = px.bar(
                url_impact.reset_index(),
                x='volume_impacte',
                y='url',
                orientation='h',
                color_discrete_sequence=['#EF4444']
            )
            fig_bar.update_layout(yaxis={'categoryorder': 'total ascending'}, height=400)
            st.plotly_chart(fig_bar, use_container_width=True)
    
    # ==========================================================================
    # TAB 2 : PERTES CRITIQUES
    # ==========================================================================
    
    with tab2:
        st.header("üî¥ Pertes critiques")
        st.markdown("Mots-cl√©s tri√©s par **score de priorit√©** (volume √ó diff √ó facteur position)")
        
        df_pertes = df_filtered[df_filtered['diff_pos'] < 0].sort_values('priority_score', ascending=False)
        
        st.info(f"**{len(df_pertes):,}** mots-cl√©s en perte de position")
        
        # Colonnes √† afficher
        cols_display = ['mot_cle', 'url', 'ancienne_pos', 'derniere_pos', 'diff_pos', 'volume', 'trafic', 'priority_score']
        cols_display = [c for c in cols_display if c in df_pertes.columns]
        
        st.dataframe(
            df_pertes[cols_display].head(500),
            use_container_width=True,
            height=600
        )
        
        # Export
        csv_pertes = df_pertes[cols_display].to_csv(index=False, sep=';').encode('utf-8')
        st.download_button(
            "üì• Exporter les pertes critiques (CSV)",
            csv_pertes,
            "pertes_critiques.csv",
            "text/csv"
        )
    
    # ==========================================================================
    # TAB 3 : PAR URL
    # ==========================================================================
    
    with tab3:
        st.header("üìÅ Analyse par URL")
        
        if 'url' in df_filtered.columns:
            # Agr√©gation par URL
            url_stats = df_filtered.groupby('url').agg({
                'mot_cle': 'count',
                'diff_pos': ['sum', 'mean'],
                'volume': 'sum',
                'trafic': 'sum',
                'priority_score': 'sum'
            }).reset_index()
            
            url_stats.columns = ['url', 'total_kw', 'diff_total', 'diff_moyen', 'volume_total', 'trafic_total', 'score_priorite']
            
            # KW en perte par URL
            pertes_par_url = df_filtered[df_filtered['diff_pos'] < 0].groupby('url').size().reset_index(name='kw_en_perte')
            url_stats = url_stats.merge(pertes_par_url, on='url', how='left')
            url_stats['kw_en_perte'] = url_stats['kw_en_perte'].fillna(0).astype(int)
            
            # Score de sant√©
            url_stats['sante_pct'] = ((url_stats['total_kw'] - url_stats['kw_en_perte']) / url_stats['total_kw'] * 100).round(1)
            
            url_stats = url_stats.sort_values('score_priorite', ascending=False)
            
            st.info(f"**{len(url_stats):,}** URLs analys√©es")
            
            st.dataframe(
                url_stats.head(200),
                use_container_width=True,
                height=500
            )
            
            # D√©tail d'une URL
            st.subheader("üîç D√©tail d'une URL")
            url_selectionnee = st.selectbox("S√©lectionner une URL", url_stats['url'].head(100).tolist())
            
            if url_selectionnee:
                df_url = df_filtered[df_filtered['url'] == url_selectionnee]
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("KW total", len(df_url))
                with col2:
                    st.metric("KW en perte", len(df_url[df_url['diff_pos'] < 0]))
                with col3:
                    st.metric("Volume total", f"{int(df_url['volume'].fillna(0).sum()):,}")
                
                cols_url = ['mot_cle', 'ancienne_pos', 'derniere_pos', 'diff_pos', 'volume', 'statut']
                cols_url = [c for c in cols_url if c in df_url.columns]
                st.dataframe(df_url[cols_url], use_container_width=True)
        else:
            st.warning("Colonne 'url' non d√©tect√©e dans le fichier")
    
    # ==========================================================================
    # TAB 4 : QUICK WINS
    # ==========================================================================
    
    with tab4:
        st.header("‚ö° Quick wins ‚Äî Opportunit√©s de r√©cup√©ration")
        st.markdown("KW qui √©taient **top 10**, ont chut√©, mais ont un **potentiel de r√©cup√©ration**")
        
        if 'meilleure_pos' in df_filtered.columns and 'derniere_pos' in df_filtered.columns:
            df_quickwins = df_filtered[
                (df_filtered['meilleure_pos'] <= 10) &
                (df_filtered['derniere_pos'] > 10) &
                (df_filtered['volume'] >= 100)
            ].copy()
            
            df_quickwins = df_quickwins.sort_values('recovery_potential', ascending=False)
            
            st.success(f"**{len(df_quickwins):,}** opportunit√©s de r√©cup√©ration identifi√©es")
            
            cols_qw = ['mot_cle', 'url', 'meilleure_pos', 'derniere_pos', 'diff_pos', 'volume', 'recovery_potential']
            cols_qw = [c for c in cols_qw if c in df_quickwins.columns]
            
            st.dataframe(
                df_quickwins[cols_qw].head(500),
                use_container_width=True,
                height=600
            )
            
            csv_qw = df_quickwins[cols_qw].to_csv(index=False, sep=';').encode('utf-8')
            st.download_button(
                "üì• Exporter les quick wins (CSV)",
                csv_qw,
                "quick_wins.csv",
                "text/csv"
            )
        else:
            st.warning("Colonnes 'meilleure_pos' et/ou 'derniere_pos' non d√©tect√©es")
    
    # ==========================================================================
    # TAB 5 : SORTIS
    # ==========================================================================
    
    with tab5:
        st.header("‚ùå Mots-cl√©s sortis des SERPs")
        
        # Sortis = derni√®re position > 100 ou NaN (disparu des SERPs)
        if 'derniere_pos' in df_filtered.columns:
            df_sortis = df_filtered[(df_filtered['derniere_pos'] > 100) | (df_filtered['derniere_pos'].isna())]
        else:
            df_sortis = pd.DataFrame()
        
        if not df_sortis.empty:
            df_sortis = df_sortis.sort_values('volume', ascending=False)
            
            st.warning(f"**{len(df_sortis):,}** mots-cl√©s ont disparu des SERPs")
            
            cols_sortis = ['mot_cle', 'url', 'ancienne_pos', 'volume', 'trafic']
            cols_sortis = [c for c in cols_sortis if c in df_sortis.columns]
            
            st.dataframe(
                df_sortis[cols_sortis].head(500),
                use_container_width=True,
                height=600
            )
            
            csv_sortis = df_sortis[cols_sortis].to_csv(index=False, sep=';').encode('utf-8')
            st.download_button(
                "üì• Exporter les KW sortis (CSV)",
                csv_sortis,
                "kw_sortis.csv",
                "text/csv"
            )
        else:
            st.info("Aucun mot-cl√© sorti d√©tect√©")
    
    # ==========================================================================
    # TAB 6 : GAINS
    # ==========================================================================
    
    with tab6:
        st.header("üü¢ Gains de position")
        
        df_gains = df_filtered[df_filtered['diff_pos'] > 0].sort_values('priority_score', ascending=False)
        
        st.success(f"**{len(df_gains):,}** mots-cl√©s en progression")
        
        cols_gains = ['mot_cle', 'url', 'ancienne_pos', 'derniere_pos', 'diff_pos', 'volume', 'trafic']
        cols_gains = [c for c in cols_gains if c in df_gains.columns]
        
        st.dataframe(
            df_gains[cols_gains].head(500),
            use_container_width=True,
            height=600
        )
    
    # ==========================================================================
    # TAB 7 : RAPPORT
    # ==========================================================================
    
    with tab7:
        st.header("üìù Rapport pour l'√©quipe contenu")
        
        if st.button("üîÑ G√©n√©rer le rapport", type="primary"):
            with st.spinner("G√©n√©ration du rapport..."):
                report = generate_report(df, df_filtered, kpis)
                st.session_state['report'] = report
        
        if 'report' in st.session_state:
            st.markdown(st.session_state['report'])
            
            st.divider()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.download_button(
                    "üì• T√©l√©charger en Markdown",
                    st.session_state['report'],
                    "rapport_seo.md",
                    "text/markdown"
                )
            
            with col2:
                st.code(st.session_state['report'], language='markdown')

else:
    # √âtat initial - pas de fichier charg√©
    st.info("üëÜ Charge un fichier CSV Haloscan dans la sidebar pour commencer l'analyse")
    
    st.markdown("""
    ### üìã Format attendu
    
    Le fichier doit contenir au minimum ces colonnes :
    - `mot-cl√© (mc)` ou `keyword` ‚Äî le mot-cl√© track√©
    - `url` ‚Äî l'URL positionn√©e
    - `diff_pos` ‚Äî diff√©rentiel de position (n√©gatif = perte)
    - `volume` ‚Äî volume de recherche mensuel
    
    Colonnes optionnelles mais recommand√©es :
    - `derni√®re_pos` ‚Äî position actuelle
    - `vieille_pos` / `ancienne_pos` ‚Äî position de la p√©riode pr√©c√©dente
    - `meilleure_pos` ‚Äî meilleure position historique
    - `statut` ‚Äî perdu, gagn√©, stable, sorti...
    - `trafic` ‚Äî estimation du trafic
    
    ### üöÄ Capacit√©
    
    L'outil peut traiter des fichiers jusqu'√† **300 000+ lignes** sans probl√®me.
    """)
